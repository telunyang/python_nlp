{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f82f6ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\nlp\\Lib\\site-packages\\jieba\\_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\darren\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.714 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import jieba\n",
    "\n",
    "# 一堆句子 (也可以是一篇文章)\n",
    "documents = []\n",
    "with open(\"./cases/bert_finetune/reviews.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    for line in file:\n",
    "        document = line.split(\"\\t\")[0]\n",
    "        documents.append(document.replace('\"', ''))\n",
    "\n",
    "# 使用 jieba 進行斷詞\n",
    "docs = [jieba.lcut(doc) for doc in documents]\n",
    "\n",
    "# 將文本標記為 TaggedDocument 格式\n",
    "docs = [TaggedDocument(doc, [index]) for index, doc in enumerate(docs)]\n",
    "\n",
    "'''\n",
    "Doc2Vec 的架構\n",
    "\n",
    "dm=1: PV-DM (預設)\n",
    "dm=0: PV-DBOW\n",
    "\n",
    "補充：\n",
    "若你用 dm=0（DBOW）但又希望同時把詞向量也學好，\n",
    "通常會搭配 dbow_words=1，\n",
    "因為純 DBOW 訓練主要用「文件向量去預測詞」，\n",
    "詞向量可能不會被充分更新；\n",
    "Gensim 的討論也指出 DBOW 的詞向量\n",
    "在某些情況下可能幾乎維持初始狀態，\n",
    "若需要詞向量要開 dbow_words=1。\n",
    "'''\n",
    "\n",
    "# 建立 Doc2Vec 模型\n",
    "model = Doc2Vec(\n",
    "    docs, \n",
    "    vector_size=100, \n",
    "    window=5, \n",
    "    dm=1,\n",
    "    # dbow_words=1\n",
    "    min_count=3,\n",
    "    workers=1,\n",
    "    epochs=10, # 100/150/200/250 的結果會比較好嗎?\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef2f12d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.0259433   0.03469285 -0.00111666 -0.01868083 -0.0517282   0.05991731\n",
      " -0.03608294  0.03787555  0.04327111 -0.04207157 -0.05886843  0.05190066\n",
      "  0.04035759  0.01424964  0.02846157  0.01896484  0.00540717  0.00413444\n",
      "  0.01510719 -0.03634094 -0.02237003  0.01434521  0.02002678  0.06969702\n",
      "  0.1155225   0.00167463 -0.08651707  0.00578223 -0.02078785  0.00402548\n",
      " -0.00220096 -0.03807146 -0.00927884 -0.02685548  0.04422115  0.01393797\n",
      "  0.03549914 -0.03949668  0.06351655  0.03456078  0.02036532  0.06355887\n",
      "  0.06173351 -0.06935179 -0.00309113  0.04602892  0.03507222 -0.03324396\n",
      "  0.05610605 -0.0252912  -0.01098299 -0.04104146 -0.02276993 -0.07580889\n",
      "  0.02499072 -0.04662764 -0.10108487 -0.0250675  -0.0168791  -0.00634301\n",
      "  0.0999837   0.04270137 -0.01684773  0.04230325 -0.00868521  0.01532395\n",
      " -0.01932412 -0.01382952 -0.04301094 -0.03098823 -0.01818291 -0.05266564\n",
      "  0.00539795 -0.0301584   0.05888811  0.00661432  0.04773217  0.014603\n",
      " -0.01838144  0.00171368 -0.02243626  0.03015491 -0.03739315  0.03757819\n",
      " -0.05875247  0.02002357 -0.10758366 -0.07088919 -0.01601393  0.01578854\n",
      " -0.05166787 -0.04718005  0.06526966 -0.04429704  0.07517491  0.0536548\n",
      " -0.05579485 -0.02308931 -0.05035486 -0.06854206]\n"
     ]
    }
   ],
   "source": [
    "# 查找索引為 5 的文件向量\n",
    "vector = model.dv[5]\n",
    "\n",
    "# 輸出索引為 5 的文件向量\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbfedcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總的來說，這樣的酒店配這樣的價格還算可以，希望他趕快裝修，給我的客人留些好的印象\n",
      "['總', '的', '來', '說', '，', '這樣', '的', '酒店', '配', '這樣', '的', '價格', '還算', '可以', '，', '希望', '他', '趕快', '裝修', '，', '給我', '的', '客人', '留些', '好', '的', '印象']\n",
      "價格比比較不錯的酒店。這次免費升級了，感謝前臺服務員。房子還好，地毯是新的，比上次的好些。早餐的人很多要早去些。\n",
      "['價格', '比比', '較', '不錯', '的', '酒店', '。', '這次', '免費', '升級', '了', '，', '感謝', '前', '臺', '服務員', '。', '房子', '還好', '，', '地毯', '是', '新', '的', '，', '比', '上次', '的', '好些', '。', '早餐', '的', '人', '很多', '要', '早', '去', '些', '。']\n"
     ]
    }
   ],
   "source": [
    "# 顯示兩個段落的文字\n",
    "print(documents[5])\n",
    "print(docs[5].words)\n",
    "\n",
    "print(documents[6])\n",
    "print(docs[6].words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37b8d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 儲存模型\n",
    "model.save('doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b123fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取模型\n",
    "model = Doc2Vec.load('doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fc3071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "總的來說，這樣的酒店配這樣的價格還算可以，希望他趕快裝修，給我的客人留些好的印象\n",
      "[(2655, 0.7628684639930725), (3866, 0.7176622152328491), (68, 0.713477373123169), (6555, 0.7029337882995605), (6292, 0.7018665671348572)]\n",
      "\n",
      "==================================================\n",
      "Doc ID: 2655, content: 客人很滿意,我們也推薦其他同事入住.價效比好.交通方便,離火車站就5分鐘路程\n",
      "0.7628684639930725\n",
      "==================================================\n",
      "Doc ID: 3866, content: 房間不錯，朋友很滿意，價格很實惠，服務態度很好\n",
      "0.7176622152328491\n",
      "==================================================\n",
      "Doc ID: 68, content: 住過好多次這家酒店了，上次來到前臺，服務員能準確的報出我的名字，感覺很親切。四星級就是不一樣。而且當天服務員還給我安排了一間商務單間，房間很新，比我訂的要好價格沒變。說是酒店搞活動，像我們這樣的商務客人都有機會享受，不錯。\n",
      "0.713477373123169\n",
      "==================================================\n",
      "Doc ID: 6555, content: 不知前面幾位朋友怎麼評價的，反正我自己入住後感覺實在不好，CHACKIN\n",
      "0.7029337882995605\n",
      "==================================================\n",
      "Doc ID: 6292, content: 大年初一入住的，酒店的裝修不錯，可是前臺服務就一位男生，態度很冷淡，感覺不希望我們入住似的，因為是探親的所以就晚上住一下，所以訂了標準房，他一開口就要我們加錢換好點的房間，我們就是衝那個價去的，如果要出四百多我們選擇其他酒店了，也不會住他家了，地方那麼偏，於是他給我們了普通的房間，那個房間真是小啊，比一百元多的連鎖酒店還小，裝修不錯，床比較舒服，不過下次肯定不會住這家了。不實惠，而且因為在網上看到送迷你吧和可以免費去植物園的，前臺的也沒有交代這些事情，如果沒有在網上看到的人肯定不知道的。\n",
      "0.7018665671348572\n"
     ]
    }
   ],
   "source": [
    "# 查找索引為 5 的文件向量\n",
    "print(documents[5])\n",
    "\n",
    "# 找前 10 個相似的文件\n",
    "similar_docs = model.dv.most_similar(5, topn=5)\n",
    "print(similar_docs)\n",
    "print()\n",
    "\n",
    "for doc_index, similarity in similar_docs:\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Doc ID: {doc_index}, content: {documents[doc_index]}\")\n",
    "    print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ad85c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "距離川沙公路較近,但是公交指示不對,如果是蔡陸線的話,會非常麻煩.建議用別的路線.房間較為簡單.\n",
      "價格適中，裝修還可以。早餐尚可。物有所值\n",
      "0.5960297\n"
     ]
    }
   ],
   "source": [
    "# 查找索引為 5 的文件向量\n",
    "print(documents[0])\n",
    "\n",
    "# 查找索引為 843 的文件向量\n",
    "print(documents[843])\n",
    "\n",
    "# 計算文檔向量 0 和文檔向量 843 之間的相似度\n",
    "similarity = model.dv.similarity(5, 843)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ac1c8",
   "metadata": {},
   "source": [
    "# 如何找到合適的 epoch 數量？ (Deprecated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba4857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import jieba, random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('font', family='Microsoft JhengHei')\n",
    "\n",
    "# 讀取文本\n",
    "documents = []\n",
    "with open(\"./cases/bert_finetune/reviews.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        doc = line.split(\"\\t\")[0].replace('\"', '')\n",
    "        documents.append(doc)\n",
    "\n",
    "docs = [jieba.lcut(d) for d in documents]\n",
    "docs = [TaggedDocument(words=ws, tags=[i]) for i, ws in enumerate(docs)]\n",
    "\n",
    "# 建模（建議明確指定 dm；下面示範 dm=1）\n",
    "model = Doc2Vec(\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=3,\n",
    "    dm=1, # 或 dm=0\n",
    "    workers=4,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# 建立模型的詞彙表與文件標籤索引\n",
    "model.build_vocab(docs)\n",
    "\n",
    "# 定義訓練的 epoch 數\n",
    "num_epochs = 50\n",
    "\n",
    "# 一開始的學習率\n",
    "start_alpha = 0.025\n",
    "\n",
    "# 最後的學習率\n",
    "end_alpha = 0.0005\n",
    "\n",
    "# 每跑完一個 epoch，學習率要下降多少（線性下降）\n",
    "alpha_delta = (start_alpha - end_alpha) / num_epochs\n",
    "\n",
    "# 用於儲存每個 epoch 的損失值\n",
    "losses = []\n",
    "\n",
    "# 檢視每一回合訓練後的損失值\n",
    "for epoch in range(num_epochs):\n",
    "    # 每個 epoch 開始前把文件順序打亂\n",
    "    random.shuffle(docs)\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(f'訓練第 {epoch+1} 個 epoch')\n",
    "\n",
    "    # 線性更新學習率\n",
    "    a0 = start_alpha - epoch * alpha_delta\n",
    "    a1 = start_alpha - (epoch + 1) * alpha_delta\n",
    "\n",
    "    # 訓練\n",
    "    model.train(\n",
    "        docs,\n",
    "        total_examples=model.corpus_count,\n",
    "        epochs=1,\n",
    "        start_alpha=a0,\n",
    "        end_alpha=a1,\n",
    "        compute_loss=True\n",
    "    )\n",
    "\n",
    "    # 取得當前的損失值\n",
    "    loss = model.get_latest_training_loss()\n",
    "    losses.append(loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1:02d} | alpha {a0:.5f}->{a1:.5f} | Loss {loss}\")\n",
    "\n",
    "plt.plot(range(1, num_epochs+1), losses)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (per-epoch delta)\")\n",
    "plt.title(\"Doc2Vec 每個 epoch 的 loss\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
