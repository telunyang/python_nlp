{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8ae891d",
   "metadata": {},
   "source": [
    "# 使用 Jieba 分詞工具\n",
    "- [jieba](https://github.com/fxsjy/jieba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "923c4e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\nlp\\Lib\\site-packages\\jieba\\_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "# 匯入套件\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a65129",
   "metadata": {},
   "source": [
    "# 嘗式簡單地分詞，以及去除停用詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279d41f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\darren\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.904 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 輸入文本\n",
    "text = \"這是使用 Jieba 和 sklearn 進行中文字預處理的範例。\"\n",
    "\n",
    "# 分詞 (cut 是用於 iteration 的斷詞函式，lcut 是將斷詞以 list 格式回傳)\n",
    "tokens = jieba.lcut(text)\n",
    "\n",
    "# 去除停用詞，這邊為了簡化，我們預先定義一個停用詞列表\n",
    "stop_words = ['和', '的', '是', '這']\n",
    "tokens = [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17c57c2",
   "metadata": {},
   "source": [
    "# 自定義字典補充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc68a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取自定義的字典\n",
    "# 格式: 詞語 詞頻(可省略) 詞性(可省略)\n",
    "# jieba.load_userdict('./dict.txt')\n",
    "\n",
    "# 自定義字詞 (執行一次就會存在 memory 中，要重啟 kernel 才會失效)\n",
    "# jieba.add_word('網球史上')\n",
    "# jieba.add_word('網球運動員')\n",
    "# jieba.add_word('單打冠軍')\n",
    "# jieba.add_word('冠軍')\n",
    "# jieba.add_word('大滿貫')\n",
    "# jieba.add_word('總決賽')\n",
    "# jieba.add_word('大師賽')\n",
    "\n",
    "# Optional: 你也可以移除自定義的字詞\n",
    "# jieba.del_word('網球史上')\n",
    "\n",
    "# 輸入文本\n",
    "text = '''\\\n",
    "羅傑費德勒，已退役的瑞士男子職業網球運動員，費德勒總共贏得20座大滿貫冠軍，單打世界排名第一累計310周，\n",
    "其中包括連續237周世界排名第一的男子網壇紀錄，為網球史上最佳的男子選手之一。\n",
    "費德勒生涯贏得103個ATP單打冠軍，含20座大滿貫冠軍和6座ATP年終總決賽冠軍，以及28座大師賽冠軍。\n",
    "'''\n",
    "\n",
    "# 分詞 (cut 是用於回傳 generator 的斷詞函式，lcut 是將斷詞以 list 格式回傳)\n",
    "tokens = jieba.lcut(text)\n",
    "\n",
    "# 去除停用詞，這邊為了簡化，我們預先定義一個停用詞列表\n",
    "stop_words = ['和', '的', '是', '這']\n",
    "tokens = [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e382c7a",
   "metadata": {},
   "source": [
    "# 中文的 Part-of-Speech tagging\n",
    "- 資料來源：[https://github.com/fxsjy/jieba?tab=readme-ov-file#%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B](https://github.com/fxsjy/jieba?tab=readme-ov-file#%E4%BD%BF%E7%94%A8%E7%A4%BA%E4%BE%8B)\n",
    "\n",
    "| 標籤 | 意義 | 標籤 | 意義 | 標籤 | 意義 | 標籤 | 意義 |\n",
    "|---|---|---|---|---|---|---|---|\n",
    "| n  | 普通名詞 | f  | 方位名詞 | s  | 處所名詞 | t    | 時間 |\n",
    "| nr | 人名     | ns | 地名     | nt | 機構名   | nw   | 作品名 |\n",
    "| nz | 其他專名 | v  | 普通動詞 | vd | 動副詞   | vn   | 名動詞 |\n",
    "| a  | 形容詞   | ad | 副形詞   | an | 名形詞   | d    | 副詞 |\n",
    "| m  | 數量詞   | q  | 量詞     | r  | 代名詞   | p    | 介詞 |\n",
    "| c  | 連接詞   | u  | 助詞     | xc | 其他虛詞 | w    | 標點符號 |\n",
    "| PER | 人名    | LOC | 地名    | ORG | 機構名  | TIME | 時間 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85e8443e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我 r\n",
      "喜歡 v\n",
      "看 v\n",
      "電影 n\n"
     ]
    }
   ],
   "source": [
    "# POS tagging\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "# 假設我們有以下句子\n",
    "sentence = \"我喜歡看電影\"\n",
    "\n",
    "# 使用jieba進行詞性標注\n",
    "words = pseg.cut(sentence)\n",
    "\n",
    "# 列印每個詞及其詞性\n",
    "for word, flag in words:\n",
    "    print(f'{word} {flag}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
